# Despliegue y Monitoreo de un Modelo de Machine Learning para Clasificaci√≥n de Clientes

<ins>Integrantes</ins>: Tom√°s Azema Di Pizio, Leonardo Rivadeneira, Priscila Moreno.<br>
<ins>Profesor</ins>: Diego Mosquera<br>
<ins>Materia</ins>: Laboratorio de Miner√≠a de Datos<br>
<ins>Comisi√≥n</ins>: Martes de 19 a 21 hs<br>
<ins>Instituo</ins>: [ISTEA](https://www.istea.edu.ar/) - Instituto Superior T√©cnico Empresarial Argentino<br>

<ins>URL de la API</ins>: http://0092feb4-419f-4ffe-b55a-0455af0d5b9b.brazilsouth.azurecontainer.io/score<br>
<ins>M√©todo POST</ins>: Env√≠ar el siguiente c√≥digo crudo (raw) de JSON
```json
{
  "age": 56,
  "gender": "Male",
  "annual_income": 65648,
  "total_spent": 49624,
  "num_purchases": 17,
  "avg_purchase_value": 467,
  "online_activity_score": 52,
  "loyalty_program": 0,
  "days_since_last_purchase": 235,
  "num_site_visits": 61
}
```

![Portada](img/portada.png)

---

### √çndice

- [Contexto](#contexto)
- [1. An√°lisis y preprocesamiento de datos](#1-an√°lisis-y-preprocesamiento-de-datos)
- [2. Entrenamiento del modelo](#2-entrenamiento-del-modelo)
- [3. Empaquetado y despliegue del modelo](#3-empaquetado-y-despliegue-del-modelo)
- [4. Monitoreo y mantenimiento del modelo](#4-monitoreo-y-mantenimiento-del-modelo)

---

### Contexto

Una empresa minorista quiere implementar un sistema de recomendaci√≥n de productos personalizado. El primer paso es clasificar a los clientes en diferentes categor√≠as (por ejemplo, "alto valor", "frecuente", "ocasional", etc.) bas√°ndose en datos hist√≥ricos de compras y comportamiento de los usuarios. Una vez que se entrena el modelo de clasificaci√≥n, debe ser desplegado para que el equipo de marketing pueda usarlo en tiempo real.

### 1. An√°lisis y preprocesamiento de datos

En el marco del contexto explicado en el punto anterior, se analizan los datos existentes en el archivo ‚Äú*synthetic_customer_data.csv*‚Äù. Utilizando un cuaderno de jupyter notebook, en primer lugar se describe la estructura del set de datos:

![df.info()](img/df_info.png)

El **√∫ltimo campo**, llamado *customer_segment*, representa el valor que tiene cada cliente para la empresa, indicado como bajo, medio o alto (low, medium o high). Esta ser√° nuestra variable independiente, es decir, aquella **variable a predecir por el modelo**. Con excepci√≥n de *customer_id*, **el resto de columnas ser√°n las columnas de entrada** que recibir√° nuestro modelo de machine learning, nuestras variables dependientes.

**Luego de confirmar que no hay valores nulos o filas duplicadas, se procede a realizar una transformaci√≥n de la columna *gender*. Se transforma la columna de categ√≥rica a numerica con** `OneHotEncoder`. Como resultado, se obtienen dos columnas nuevas: una llamada *gender_female* y la otra *gender_male*. A modo de bandera, cuando uno de estos campos contiene un ‚Äú1‚Äù significa que el cliente del registro pertenece a dicho g√©nero, y por ende, se anotar√° un ‚Äú0‚Äù en la otra columna.

As√≠ nos quedar√≠a el conjunto de datos con el cual el modelo ser√° entrenado.

![nuevo dataframe](img/nuevo_df.png)

---

### 2. Entrenamiento del modelo

Se divide el set de datos, cre√°ndose dos subconjuntos: uno para entrenamiento y el otro para testing, con una proporci√≥n de 80 % y 20 % respectivamente. **Se desarrolla un modelo de clasificaci√≥n de bosque aleatorio**, instanciando a `RandomForestClassifier()` de `scikit-learn`. A continuaci√≥n, se entrena, se valida y se eval√∫a el modelo.

**El modelo obtiene muy buenos resultados, destacando un 98% de precisi√≥n**. Al revisar y visualizar la importancia de cada ‚Äúfeature‚Äù (cada columna o campo en este caso), podemos ver que campo es m√°s importante para el modelo.

![feature importances](img/feature_importances.png)

**Se procede a hacer una revisi√≥n de los hiper par√°metros del modelo con el objetivo de mejorar su rendimiento**. En este caso, el modelo utiliza el √≠ndice de gini como criterio; **se procede a utilizar el √≠ndice de entrop√≠a como nuevo criterio** con el fin de obtener mejores resultados, o confirmar si el criterio por defecto ofrece el mejor rendimiento posible. 

**Si bien hab√≠a poco margen de mejora, el modelo ahora obtiene un 99,5% de precisi√≥n**, adem√°s de mejorar en otras m√©tricas como el recall o el f1-score.

---

### 3. Empaquetado y despliegue del modelo

Utilizando la librer√≠a `joblib`, se serializa y exporta el modelo en un archivo pickle (de extensi√≥n .pkl) llamado ‚Äú*random_forest_model.pkl*‚Äù. Este archivo es el que despu√©s se utilizar√° para el despliegue del modelo.

```python
ruta = 'models/random_forest_model.pkl'
joblib.dump(rf_model, ruta)
```

Previo a registrar y desplegar el modelo en Azure, hacemos una API en nuestro cuaderno jupyter notebook (que para nosotros es nuestro √°rea de desarrollo). En el mismo, se utilizar√° la librer√≠a `flask` para crear una API RestFul.

Entre otras cosas, aqu√≠ se practic√≥ el hecho de como los datos seran entregados al modelo y devueltos por la API. Por ejemplo, los datos de entrada poseer√°n al genero como una variable de texto, que deber√° ser transformada a dos columnas num√©ricas por la funci√≥n de predicci√≥n.

#### Creando una instancia de Flask

```python
# Instancia de la aplicaci√≥n de Flask
app = Flask(__name__)

@app.route("/", methods = ['GET'])
def index():
    return "M√©todo GET de comprobaci√≥n"

# Define una ruta en el servidor Flask que responde a las solicitudes HTTP POST
@app.route("/predict", methods = ['POST'])

def predict():
    try:
        data = request.get_json(force=True)  # Obtiene los datos del request en formato JSON
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        # Convertir el g√©nero a one-hot encoding
        gender = data['gender']
        gender_female = 1.0 if gender == 'Female' else 0.0
        gender_male = 1.0 if gender == 'Male' else 0.0
        
        # Formatear los datos en el formato que el modelo espera
        features = [
            data['age'], data['annual_income'], data['total_spent'], 
            data['num_purchases'], data['avg_purchase_value'], data['online_activity_score'], 
            data['loyalty_program'], data['days_since_last_purchase'], data['num_site_visits'], 
            gender_female, gender_male
        ]
        
        # Realiza la predicci√≥n
        prediction = model.predict([features])
        
        # Devuelve la predicci√≥n en formato JSON
        return jsonify({'prediction': prediction.tolist()})
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def run_app():
    app.run(host = '0.0.0.0', port = 5000)

thread = Thread(target = run_app)
thread.start()
```

Se realizan dos pruebas y en ambos casos se obtiene un c√≥digo 200: no solo se obtiene una predicci√≥n, sino que tambi√©n esta misma es ‚Äúrazonable‚Äù en base al criterio proporcionado.

```python
url = 'http://127.0.0.1:5000/predict'

usuario_test = {
  "age": 56,
  "gender": "Male",
  "annual_income": 65648,
  "total_spent": 49624,
  "num_purchases": 17,
  "avg_purchase_value": 467,
  "online_activity_score": 52,
  "loyalty_program": 0,
  "days_since_last_purchase": 235,
  "num_site_visits": 61
}

response = requests.post(url, json = usuario_test)

print(response.json())
```

```bash
127.0.0.1 - - [14/Nov/2024 02:13:34] "POST /predict HTTP/1.1" 200 -
{'prediction': ['medium_value']}
```

Conclu√≠da esta prueba, ahora si estamos en condiciones de registrar y desplegar el modelo. **Hasta el momento ven√≠amos trabajando en jupyter notebook alojado en Google Colab. Ahora, procederemos a utilizar Azure**, cre√°ndose un √°rea de trabajo de Machine Learning (ML Studio o AML) y un grupo de recursos. Se subir√°n o crear√°n los archivos necesarios y se crear√° una instancia de proceso.

![](img/azure.png)

Los archivos de programaci√≥n se utilizar√°n por separado (en vez de un solo notebook). En todos los archivos, va a ser necesario estar conectado al area de trabajo utilizando la siguiente l√≠nea de python: `ws = Workspace.from_config()`.

```
‚îú‚îÄ‚îÄ üìÇ data
‚îÇ   ‚îú‚îÄ‚îÄ synthetic_customer_data.csv
‚îú‚îÄ‚îÄ üìÇ models
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_model.pkl
‚îú‚îÄ‚îÄ üìÇ scripts
‚îÇ   ‚îú‚îÄ‚îÄ despliegue_modelo.py
‚îÇ   ‚îú‚îÄ‚îÄ registro_modelo.py
‚îÇ   ‚îú‚îÄ‚îÄ score.py
‚îÇ   ‚îú‚îÄ‚îÄ test.json
‚îú‚îÄ‚îÄ noteboook.ipynb
‚îî‚îÄ‚îÄ run.sh
```

En primer lugar, se ejecutar√° el archivo ‚Äú**registro_modelo.py**‚Äù, que, como bien indica el nombre, registrar√° el modelo en el servicio de Azure ML Studio.

```python
from azureml.core import Workspace
from azureml.core.model import Model

# Conectarse al √°rea de trabajo
ws = Workspace.from_config()

# Variables
ruta = "../models/random_forest_model.pkl"
nombre_modelo = 'rf_model'

# Registrar el modelo en el √°rea de trabajo
model = Model.register(workspace = ws,
                       model_name = nombre_modelo,
                       model_path = "../models/random_forest_model.pkl")

# Resultado esperado: "Registering model rf_model"
```

Una vez registrado el modelo, nos aseguraremos de tener el archivo ‚Äú**score.py**‚Äù subido a la plataforma. Aqu√≠ dentro es donde desarrollaremos la implementaci√≥n del modelo y el formato de la entrada de sus par√°metros. Es similar al que se encuentra en el notebook, solo que este esta dise√±ado para su posterior implementaci√≥n en un punto de conexi√≥n de Azure.

```python
from flask import request, jsonify
import joblib
import os

def init():
    global rf_model
    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'random_forest_model.pkl')
    rf_model = joblib.load(model_path)

def run(data):
    try:
        data = request.get_json(force=True)

        # Convertir el g√©nero a one-hot encoding
        gender = data['gender']
        gender_female = 1.0 if gender == 'Female' else 0.0
        gender_male = 1.0 if gender == 'Male' else 0.0
        
        # Formatear los datos en el formato que el modelo espera
        features = [
            data['age'], data['annual_income'], data['total_spent'], 
            data['num_purchases'], data['avg_purchase_value'], data['online_activity_score'], 
            data['loyalty_program'], data['days_since_last_purchase'], data['num_site_visits'], 
            gender_female, gender_male
        ]
        
        # Realiza la predicci√≥n
        result = rf_model.predict([features])
        return jsonify({'prediction': result.tolist()})
        
    except Exception as e:
        error = jsonify({'error': str(e)}), 500
        return error
```

En √∫ltima instancia, se ejecutar√° el archivo ‚Äú**despliegue_modelo.py**‚Äù. Este crear√° nuestro punto de conexi√≥n en donde podremos env√≠ar peticiones al modelo para esperar una respuesta. Se define un entorno de `azureml.core.environment` y se agregar√°n las dependencias necesarias. Se ajustan dos elementos de configuraci√≥n: `InferenceConfig` y `AciWebservice`.

```python
from azureml.core import Workspace
from registro_modelo import nombre_modelo

# librerias de entorno
from azureml.core.environment import Environment
from azureml.core.conda_dependencies import CondaDependencies
# librerias de despliegue
from azureml.core.model import Model, InferenceConfig
from azureml.core.webservice import AciWebservice, Webservice

# Conectarse al √°rea de trabajo
ws = Workspace.from_config()

# variables
nombre_servicio = 'rf-model-servicio'

# Cargar el modelo
model = Model(ws, nombre_modelo)

# Definir el entorno
env = Environment(name="proyecto_env")
conda_dep = CondaDependencies()
conda_dep.add_conda_package("scikit-learn")
conda_dep.add_conda_package("pandas")
conda_dep.add_conda_package("flask")
env.python.conda_dependencies = conda_dep

env.register(workspace=ws)

# Configurar la inferencia
inference_config = InferenceConfig(entry_script="score.py", environment=env)

# Configurar el despliegue ACI
aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)

# Desplegar el modelo como un servicio web
service = Model.deploy(ws, nombre_servicio, [model], inference_config=inference_config, deployment_config=aci_config)
service.wait_for_deployment(show_output=True)
print(service.state)

uri = service.scoring_uri
print(f'Direcci√≥n URI a la cual enviar las peticiones: {uri}')

```

**Se realizaron pruebas y comprobaciones finales utilizando el servicio de [Postman](https://www.postman.com/)**. Se le pas√≥ la URL generada por Azure para env√≠ar peticiones, y una petici√≥n como prueba.

Se obtuvo como resultado un c√≥digo 200, indicando que no hubo errores en el transcurso. El valor devuelto es una predicci√≥n, con el segmento del cliente como resultado.

![](img/postman.png)

---

### 4. Monitoreo y mantenimiento del modelo

En esta etapa del proyecto se implementa el seguimiento y la gesti√≥n del modelo utilizando **MLflow**. Para permitir el acceso remoto a la interfaz de usuario de MLflow, se utiliza un t√∫nel seguro configurado con **ngrok**.

#### <ins>Bibliotecas Utilizadas</ins>

Se instalan mlflow y pyngrok para el seguimiento de modelos de aprendizaje autom√°tico, el registro de modelos y la implementaci√≥n.

```python
!pip install mlflow
!pip install pyngrok
```

Ahora si, se importan las librer√≠as.

```python
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
```

#### <ins>Configuraci√≥n de MLflow</ins>

```python
# Se establece el modelo en MLflow
mlflow.set_experiment('proyecto')

# Esta l√≠nea es importante para asegurar que no haya ejecuciones activas antes de comenzar una nueva.

if mlflow.active_run() is not None: 
    mlflow.end_run()
```

#### <ins>Entrenamiento y registro del modelo</ins>

```python
with mlflow.start_run()
    # Define y entrenae el modelo
    rf_model = RandomForestClassifier(n_estimators=10)
    rf_model.fit(X_train, y_train)

    mlflow.log_param("n_estimators", 10)
```

```python
y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Serializando el modelo
mlflow.sklearn.log_model(rf_model, "RandomForestModel")
```

#### <ins>Configuraci√≥n y ejecuci√≥n de ngrok</ins>

```python
# Activando el servidor
get_ipython().system_raw("mlflow ui --port 5000 &")
```

```python
from pyngrok import ngrok

ngrok.kill()

NGROK_AUTH_TOKEN = "2p2khEow4fR9Jyb9mIIWfDwPFj4_7hFMxUFE2PXQBCBRNxcL3"
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

ngrok_tunnel = ngrok.connect(addr="5000", proto="http", bind_tls=True)

print("Url para MLFLOW: ", ngrok_tunnel.public_url)
```

![](img/mlflow_1.png)

![](img/mlflow_2.png)

![](img/mlflow_metrics.png)

---

[üè† Ir al inicio](#despliegue-y-monitoreo-de-un-modelo-de-machine-learning-para-clasificaci√≥n-de-clientes)